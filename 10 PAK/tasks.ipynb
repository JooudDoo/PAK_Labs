{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С помощью библиотеки np реализовать модель с прямым проходом, состоящую из 3 полносвязных слоём с функциями потерь: ReLU, tanh, Softmax. Длины векторов на входе 256, на выходе 4, промежуточные: 64 и 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(inputs):\n",
    "    return np.maximum(0,inputs)\n",
    "\n",
    "def tanh(inputs):\n",
    "    return np.tanh(inputs)\n",
    "\n",
    "def softMax(inputs):\n",
    "    exponentsSum = np.sum(np.exp(inputs))\n",
    "    f = np.vectorize(lambda x: np.exp(x)/exponentsSum)\n",
    "    return f(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "\n",
    "    def __init__(self, size, lossFuncs = []):\n",
    "        self.weights = np.random.random(size)\n",
    "        self.lossFuncs = lossFuncs\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        result = inputs.dot(self.weights)\n",
    "        for f in self.lossFuncs:\n",
    "            result = f(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43849241, 0.25346715, 0.04080575, 0.26723469]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "inputs = np.random.randint(0, 255, size=(1, 256))\n",
    "Neuron_1 = Layer((256, 64), [ReLU])\n",
    "Neuron_2 = Layer((64, 16), [ReLU, tanh])\n",
    "Neuron_3 = Layer((16, 4), [ReLU, softMax])\n",
    "\n",
    "conveyorFirstTask = [Neuron_1, Neuron_2, Neuron_3]\n",
    "\n",
    "result = inputs\n",
    "for Layer in conveyorFirstTask:\n",
    "    result = Layer(result)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализовать модель с прямым проходом, состоящую из 2 свёрток с функциями активации ReLU и 2 функций MaxPool. Первый слой переводит из 3 каналов в 8, второй из 8 слоёв в 16. На вход подаётся изображение размера 19х19. (19х19x3 -> 18x18x8 -> 9x9x8 -> 8x8x16 -> 4x4x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldLayer():\n",
    "\n",
    "    def __init__(self, sizeIn, sizeOut, kernelSize, pad, step, activationFunc = ReLU):\n",
    "        self.pad = pad\n",
    "        self.step = step\n",
    "        self.sIx, self.sIy, self.sIc = sizeIn\n",
    "        self.sOx, self.sOy, self.sOc = sizeOut\n",
    "        self.activatation = activationFunc\n",
    "\n",
    "        self.weights = []\n",
    "        for _ in range(sizeOut[2]):\n",
    "            self.weights.append(np.random.random((kernelSize, kernelSize, self.sIc)))\n",
    "        self.weights = np.array(self.weights)\n",
    "\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ny, nx, nc = inputs.shape\n",
    "    \n",
    "        result = np.zeros((ny-1, nx-1, self.sOc)) \n",
    "\n",
    "        for ind, weight in enumerate(self.weights):\n",
    "            applied = convolution(inputs, weight, step=self.step)\n",
    "            result[:, :, ind] = applied[:, :]\n",
    "        \n",
    "        return self.activatation(result)\n",
    "\n",
    "class MaxPoolLayer():\n",
    "\n",
    "    def __init__(self, kernelSize, step):\n",
    "        self.step = step\n",
    "        self.kernelSize = kernelSize\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        result = maxPool(inputs, self.kernelSize, step=self.step)\n",
    "        return result\n",
    "\n",
    "def maxPool(x, kernelSize : int, step):\n",
    "    inX, inY, inC = x.shape\n",
    "    maxPoolResult = np.zeros((inX//kernelSize, inY//kernelSize, inC))\n",
    "\n",
    "    for channel in range(inC):\n",
    "        for v_shift in range(0, inX - kernelSize + 1, step):\n",
    "            for h_shift in range(0, inY - kernelSize + 1, step):\n",
    "                maxPoolResult[v_shift//kernelSize][h_shift//kernelSize][channel] = np.max(x[v_shift:v_shift+kernelSize,h_shift:h_shift+kernelSize,channel])\n",
    "    return maxPoolResult\n",
    "\n",
    "def pad(matr, pad1, pad2=None):\n",
    "    if not pad2:\n",
    "        pad2 = pad1\n",
    "    x, y, c = matr.shape\n",
    "    resMatr = np.zeros((x+pad1+pad2, y+pad1+pad2, c))\n",
    "    resMatr[pad1:-pad2, pad1:-pad2] = matr\n",
    "    return resMatr\n",
    "\n",
    "def convolution(x, kernel, step):\n",
    "    if x.shape[2] != kernel.shape[2]:\n",
    "        raise ValueError(\"Shapes must be same\")\n",
    "    \n",
    "    inX, inY, inC = x.shape\n",
    "    kX, kY, kC = kernel.shape\n",
    "\n",
    "    convResult = np.zeros((inX-1, inY-1, x.shape[2]))\n",
    "    for channel in range(inC):\n",
    "        for v_shift in range(0, inX - kX + 1, step):\n",
    "            for h_shift in range(0, inY - kY + 1, step):\n",
    "                convResult[v_shift][h_shift][channel] = np.sum(\n",
    "                    x[v_shift:v_shift+kX,h_shift:h_shift+kY,channel] * kernel[:,:,channel]\n",
    "                )\n",
    "    convResult = np.sum(convResult, axis=2)\n",
    "    return (convResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19, 3)\n",
      "(18, 18, 8)\n",
      "(9, 9, 8)\n",
      "(8, 8, 16)\n",
      "(4, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "inputs = np.random.randint(0, 255, size=(19,19,3))\n",
    "\n",
    "fst = FoldLayer((19,19,3), (18,18,8), kernelSize=3, pad=0, step=1)\n",
    "snd = MaxPoolLayer(2, 2)\n",
    "thrd = FoldLayer((9,9,8), (8,8,16), 3, 0, 1)\n",
    "frt = MaxPoolLayer(2, 2)\n",
    "\n",
    "\n",
    "conveyorSecondTask = [fst, snd, thrd, frt]\n",
    "data = inputs\n",
    "print(data.shape)\n",
    "for layer in conveyorSecondTask:\n",
    "    data = layer(data)\n",
    "    print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединить сети из п.2 и п.1. На выход изображение размера 19х19, на выходе вектор из 4 элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19, 3)\n",
      "(18, 18, 8)\n",
      "(9, 9, 8)\n",
      "(8, 8, 16)\n",
      "(4, 4, 16)\n",
      "(256,)\n",
      "(64,)\n",
      "(16,)\n",
      "[0.43849241 0.25346715 0.04080575 0.26723469]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 255, size=(19,19,3))\n",
    "\n",
    "conveyorThirdTask = conveyorSecondTask + [np.ravel] + conveyorFirstTask\n",
    "\n",
    "for layer in conveyorThirdTask:\n",
    "    print(data.shape)\n",
    "    data = layer(data)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packsVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff688f89a0370a5936d2c10a3cf318be4dba0db836fb7ebaf788172d168ae0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
