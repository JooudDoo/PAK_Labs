Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [128, 10]                 --
├─Sequential: 1-1                        [128, 64, 32, 32]         --
│    └─Conv2d: 2-1                       [128, 64, 32, 32]         1,792
│    └─BatchNorm2d: 2-2                  [128, 64, 32, 32]         128
│    └─ReLU: 2-3                         [128, 64, 32, 32]         --
├─Sequential: 1-2                        [128, 128, 16, 16]        --
│    └─Conv2d: 2-4                       [128, 128, 32, 32]        73,856
│    └─BatchNorm2d: 2-5                  [128, 128, 32, 32]        256
│    └─ReLU: 2-6                         [128, 128, 32, 32]        --
│    └─MaxPool2d: 2-7                    [128, 128, 16, 16]        --
├─Sequential: 1-3                        [128, 128, 16, 16]        --
│    └─Sequential: 2-8                   [128, 128, 16, 16]        --
│    │    └─Conv2d: 3-1                  [128, 128, 16, 16]        147,584
│    │    └─BatchNorm2d: 3-2             [128, 128, 16, 16]        256
│    │    └─ReLU: 3-3                    [128, 128, 16, 16]        --
│    └─Sequential: 2-9                   [128, 128, 16, 16]        --
│    │    └─Conv2d: 3-4                  [128, 128, 16, 16]        147,584
│    │    └─BatchNorm2d: 3-5             [128, 128, 16, 16]        256
│    │    └─ReLU: 3-6                    [128, 128, 16, 16]        --
├─Sequential: 1-4                        [128, 256, 8, 8]          --
│    └─Conv2d: 2-10                      [128, 256, 16, 16]        295,168
│    └─BatchNorm2d: 2-11                 [128, 256, 16, 16]        512
│    └─ReLU: 2-12                        [128, 256, 16, 16]        --
│    └─MaxPool2d: 2-13                   [128, 256, 8, 8]          --
├─Sequential: 1-5                        [128, 512, 4, 4]          --
│    └─Conv2d: 2-14                      [128, 512, 8, 8]          1,180,160
│    └─BatchNorm2d: 2-15                 [128, 512, 8, 8]          1,024
│    └─ReLU: 2-16                        [128, 512, 8, 8]          --
│    └─MaxPool2d: 2-17                   [128, 512, 4, 4]          --
├─Sequential: 1-6                        [128, 512, 4, 4]          --
│    └─Sequential: 2-18                  [128, 512, 4, 4]          --
│    │    └─Conv2d: 3-7                  [128, 512, 4, 4]          2,359,808
│    │    └─BatchNorm2d: 3-8             [128, 512, 4, 4]          1,024
│    │    └─ReLU: 3-9                    [128, 512, 4, 4]          --
│    └─Sequential: 2-19                  [128, 512, 4, 4]          --
│    │    └─Conv2d: 3-10                 [128, 512, 4, 4]          2,359,808
│    │    └─BatchNorm2d: 3-11            [128, 512, 4, 4]          1,024
│    │    └─ReLU: 3-12                   [128, 512, 4, 4]          --
├─Sequential: 1-7                        [128, 10]                 --
│    └─MaxPool2d: 2-20                   [128, 512, 1, 1]          --
│    └─Flatten: 2-21                     [128, 512]                --
│    └─Linear: 2-22                      [128, 10]                 5,130
==========================================================================================
Total params: 6,575,370
Trainable params: 6,575,370
Non-trainable params: 0
Total mult-adds (G): 48.59
==========================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 771.76
Params size (MB): 26.30
Estimated Total Size (MB): 799.64
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [128, 10]                 --
├─Sequential: 1-1                        [128, 64, 32, 32]         --
│    └─Conv2d: 2-1                       [128, 64, 32, 32]         1,792
│    └─BatchNorm2d: 2-2                  [128, 64, 32, 32]         128
│    └─ReLU: 2-3                         [128, 64, 32, 32]         --
├─Sequential: 1-2                        [128, 128, 16, 16]        --
│    └─Conv2d: 2-4                       [128, 128, 32, 32]        73,856
│    └─BatchNorm2d: 2-5                  [128, 128, 32, 32]        256
│    └─ReLU: 2-6                         [128, 128, 32, 32]        --
│    └─MaxPool2d: 2-7                    [128, 128, 16, 16]        --
├─Sequential: 1-3                        [128, 128, 16, 16]        --
│    └─Sequential: 2-8                   [128, 128, 16, 16]        --
│    │    └─Conv2d: 3-1                  [128, 128, 16, 16]        147,584
│    │    └─BatchNorm2d: 3-2             [128, 128, 16, 16]        256
│    │    └─ReLU: 3-3                    [128, 128, 16, 16]        --
│    └─Sequential: 2-9                   [128, 128, 16, 16]        --
│    │    └─Conv2d: 3-4                  [128, 128, 16, 16]        147,584
│    │    └─BatchNorm2d: 3-5             [128, 128, 16, 16]        256
│    │    └─ReLU: 3-6                    [128, 128, 16, 16]        --
├─Sequential: 1-4                        [128, 256, 8, 8]          --
│    └─Conv2d: 2-10                      [128, 256, 16, 16]        295,168
│    └─BatchNorm2d: 2-11                 [128, 256, 16, 16]        512
│    └─ReLU: 2-12                        [128, 256, 16, 16]        --
│    └─MaxPool2d: 2-13                   [128, 256, 8, 8]          --
├─Sequential: 1-5                        [128, 512, 4, 4]          --
│    └─Conv2d: 2-14                      [128, 512, 8, 8]          1,180,160
│    └─BatchNorm2d: 2-15                 [128, 512, 8, 8]          1,024
│    └─ReLU: 2-16                        [128, 512, 8, 8]          --
│    └─MaxPool2d: 2-17                   [128, 512, 4, 4]          --
├─Sequential: 1-6                        [128, 512, 4, 4]          --
│    └─Sequential: 2-18                  [128, 512, 4, 4]          --
│    │    └─Conv2d: 3-7                  [128, 512, 4, 4]          2,359,808
│    │    └─BatchNorm2d: 3-8             [128, 512, 4, 4]          1,024
│    │    └─ReLU: 3-9                    [128, 512, 4, 4]          --
│    └─Sequential: 2-19                  [128, 512, 4, 4]          --
│    │    └─Conv2d: 3-10                 [128, 512, 4, 4]          2,359,808
│    │    └─BatchNorm2d: 3-11            [128, 512, 4, 4]          1,024
│    │    └─ReLU: 3-12                   [128, 512, 4, 4]          --
├─Sequential: 1-7                        [128, 10]                 --
│    └─MaxPool2d: 2-20                   [128, 512, 1, 1]          --
│    └─Flatten: 2-21                     [128, 512]                --
│    └─Linear: 2-22                      [128, 10]                 5,130
==========================================================================================
Total params: 6,575,370
Trainable params: 6,575,370
Non-trainable params: 0
Total mult-adds (G): 48.59
==========================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 771.76
Params size (MB): 26.30
Estimated Total Size (MB): 799.64
==========================================================================================
Using 4 GPUs
  0%|          | 0/35 [00:00<?, ?it/s]Acc: 0.2947  Avg. train/valid loss: 3.4490/2.0210:   0%|          | 0/35 [00:19<?, ?it/s]Acc: 0.2947  Avg. train/valid loss: 3.4490/2.0210:   3%|▎         | 1/35 [00:19<10:48, 19.06s/it]Acc: 0.4547  Avg. train/valid loss: 2.0369/1.5711:   3%|▎         | 1/35 [00:31<10:48, 19.06s/it]Acc: 0.4547  Avg. train/valid loss: 2.0369/1.5711:   6%|▌         | 2/35 [00:31<08:16, 15.06s/it]Acc: 0.6026  Avg. train/valid loss: 1.4253/1.1255:   6%|▌         | 2/35 [00:44<08:16, 15.06s/it]Acc: 0.6026  Avg. train/valid loss: 1.4253/1.1255:   9%|▊         | 3/35 [00:44<07:28, 14.00s/it]Acc: 0.6498  Avg. train/valid loss: 1.1493/0.9986:   9%|▊         | 3/35 [00:56<07:28, 14.00s/it]Acc: 0.6498  Avg. train/valid loss: 1.1493/0.9986:  11%|█▏        | 4/35 [00:56<06:54, 13.38s/it]Acc: 0.6537  Avg. train/valid loss: 0.9693/1.0409:  11%|█▏        | 4/35 [01:08<06:54, 13.38s/it]Acc: 0.6537  Avg. train/valid loss: 0.9693/1.0409:  14%|█▍        | 5/35 [01:08<06:31, 13.06s/it]Saved loss with acc: 0.6536999940872192 | loss: 1.0408878326416016
Acc: 0.7089  Avg. train/valid loss: 0.8150/0.8640:  14%|█▍        | 5/35 [01:21<06:31, 13.06s/it]Acc: 0.7089  Avg. train/valid loss: 0.8150/0.8640:  17%|█▋        | 6/35 [01:21<06:10, 12.76s/it]Saved loss with acc: 0.708899974822998 | loss: 0.8639603853225708
Acc: 0.7520  Avg. train/valid loss: 0.7414/0.7346:  17%|█▋        | 6/35 [01:33<06:10, 12.76s/it]Acc: 0.7520  Avg. train/valid loss: 0.7414/0.7346:  20%|██        | 7/35 [01:33<05:54, 12.66s/it]Saved loss with acc: 0.7519999742507935 | loss: 0.7345747947692871
Acc: 0.7460  Avg. train/valid loss: 0.6551/0.8302:  20%|██        | 7/35 [01:45<05:54, 12.66s/it]Acc: 0.7460  Avg. train/valid loss: 0.6551/0.8302:  23%|██▎       | 8/35 [01:45<05:38, 12.52s/it]Acc: 0.7909  Avg. train/valid loss: 0.5873/0.6478:  23%|██▎       | 8/35 [01:58<05:38, 12.52s/it]Acc: 0.7909  Avg. train/valid loss: 0.5873/0.6478:  26%|██▌       | 9/35 [01:58<05:24, 12.48s/it]Saved loss with acc: 0.7908999919891357 | loss: 0.6477965712547302
Acc: 0.8107  Avg. train/valid loss: 0.5543/0.5739:  26%|██▌       | 9/35 [02:10<05:24, 12.48s/it]Acc: 0.8107  Avg. train/valid loss: 0.5543/0.5739:  29%|██▊       | 10/35 [02:10<05:11, 12.45s/it]Saved loss with acc: 0.810699999332428 | loss: 0.5739483833312988
Acc: 0.8187  Avg. train/valid loss: 0.4995/0.5542:  29%|██▊       | 10/35 [02:22<05:11, 12.45s/it]Acc: 0.8187  Avg. train/valid loss: 0.4995/0.5542:  31%|███▏      | 11/35 [02:22<04:57, 12.41s/it]Saved loss with acc: 0.8186999559402466 | loss: 0.5542012453079224
Acc: 0.8250  Avg. train/valid loss: 0.4781/0.5172:  31%|███▏      | 11/35 [02:35<04:57, 12.41s/it]Acc: 0.8250  Avg. train/valid loss: 0.4781/0.5172:  34%|███▍      | 12/35 [02:35<04:46, 12.45s/it]Saved loss with acc: 0.824999988079071 | loss: 0.5171870589256287
Acc: 0.7988  Avg. train/valid loss: 0.4313/0.6207:  34%|███▍      | 12/35 [02:47<04:46, 12.45s/it]Acc: 0.7988  Avg. train/valid loss: 0.4313/0.6207:  37%|███▋      | 13/35 [02:47<04:33, 12.45s/it]Acc: 0.8270  Avg. train/valid loss: 0.4172/0.5370:  37%|███▋      | 13/35 [03:00<04:33, 12.45s/it]Acc: 0.8270  Avg. train/valid loss: 0.4172/0.5370:  40%|████      | 14/35 [03:00<04:21, 12.43s/it]Acc: 0.8289  Avg. train/valid loss: 0.3711/0.5303:  40%|████      | 14/35 [03:12<04:21, 12.43s/it]Acc: 0.8289  Avg. train/valid loss: 0.3711/0.5303:  43%|████▎     | 15/35 [03:12<04:08, 12.42s/it]Acc: 0.8458  Avg. train/valid loss: 0.3452/0.4546:  43%|████▎     | 15/35 [03:25<04:08, 12.42s/it]Acc: 0.8458  Avg. train/valid loss: 0.3452/0.4546:  46%|████▌     | 16/35 [03:25<03:56, 12.45s/it]Saved loss with acc: 0.84579998254776 | loss: 0.454571008682251
Acc: 0.8448  Avg. train/valid loss: 0.3319/0.4757:  46%|████▌     | 16/35 [03:37<03:56, 12.45s/it]Acc: 0.8448  Avg. train/valid loss: 0.3319/0.4757:  49%|████▊     | 17/35 [03:37<03:44, 12.45s/it]Acc: 0.8433  Avg. train/valid loss: 0.3071/0.5092:  49%|████▊     | 17/35 [03:50<03:44, 12.45s/it]Acc: 0.8433  Avg. train/valid loss: 0.3071/0.5092:  51%|█████▏    | 18/35 [03:50<03:31, 12.43s/it]Acc: 0.8151  Avg. train/valid loss: 0.2866/0.6104:  51%|█████▏    | 18/35 [04:02<03:31, 12.43s/it]Acc: 0.8151  Avg. train/valid loss: 0.2866/0.6104:  54%|█████▍    | 19/35 [04:02<03:18, 12.38s/it]Acc: 0.8347  Avg. train/valid loss: 0.2629/0.5615:  54%|█████▍    | 19/35 [04:14<03:18, 12.38s/it]Acc: 0.8347  Avg. train/valid loss: 0.2629/0.5615:  57%|█████▋    | 20/35 [04:14<03:06, 12.42s/it]Acc: 0.8518  Avg. train/valid loss: 0.2592/0.4852:  57%|█████▋    | 20/35 [04:27<03:06, 12.42s/it]Acc: 0.8518  Avg. train/valid loss: 0.2592/0.4852:  60%|██████    | 21/35 [04:27<02:55, 12.54s/it]Acc: 0.8733  Avg. train/valid loss: 0.2415/0.4110:  60%|██████    | 21/35 [04:39<02:55, 12.54s/it]Acc: 0.8733  Avg. train/valid loss: 0.2415/0.4110:  63%|██████▎   | 22/35 [04:39<02:41, 12.45s/it]Saved loss with acc: 0.8732999563217163 | loss: 0.41096121072769165
Acc: 0.8571  Avg. train/valid loss: 0.2255/0.4840:  63%|██████▎   | 22/35 [04:52<02:41, 12.45s/it]Acc: 0.8571  Avg. train/valid loss: 0.2255/0.4840:  66%|██████▌   | 23/35 [04:52<02:29, 12.47s/it]Acc: 0.8600  Avg. train/valid loss: 0.2171/0.4478:  66%|██████▌   | 23/35 [05:05<02:29, 12.47s/it]Acc: 0.8600  Avg. train/valid loss: 0.2171/0.4478:  69%|██████▊   | 24/35 [05:05<02:17, 12.54s/it]Acc: 0.8421  Avg. train/valid loss: 0.2123/0.5281:  69%|██████▊   | 24/35 [05:17<02:17, 12.54s/it]Acc: 0.8421  Avg. train/valid loss: 0.2123/0.5281:  71%|███████▏  | 25/35 [05:17<02:04, 12.45s/it]Acc: 0.8791  Avg. train/valid loss: 0.1926/0.3971:  71%|███████▏  | 25/35 [05:30<02:04, 12.45s/it]Acc: 0.8791  Avg. train/valid loss: 0.1926/0.3971:  74%|███████▍  | 26/35 [05:30<01:52, 12.54s/it]Saved loss with acc: 0.87909996509552 | loss: 0.39710044860839844
Acc: 0.8608  Avg. train/valid loss: 0.1852/0.4669:  74%|███████▍  | 26/35 [05:42<01:52, 12.54s/it]Acc: 0.8608  Avg. train/valid loss: 0.1852/0.4669:  77%|███████▋  | 27/35 [05:42<01:40, 12.53s/it]Acc: 0.8691  Avg. train/valid loss: 0.1644/0.4535:  77%|███████▋  | 27/35 [05:54<01:40, 12.53s/it]Acc: 0.8691  Avg. train/valid loss: 0.1644/0.4535:  80%|████████  | 28/35 [05:54<01:26, 12.40s/it]Acc: 0.8865  Avg. train/valid loss: 0.1695/0.3863:  80%|████████  | 28/35 [06:07<01:26, 12.40s/it]Acc: 0.8865  Avg. train/valid loss: 0.1695/0.3863:  83%|████████▎ | 29/35 [06:07<01:14, 12.45s/it]Saved loss with acc: 0.8865000009536743 | loss: 0.3862905502319336
Acc: 0.8784  Avg. train/valid loss: 0.1522/0.4221:  83%|████████▎ | 29/35 [06:19<01:14, 12.45s/it]Acc: 0.8784  Avg. train/valid loss: 0.1522/0.4221:  86%|████████▌ | 30/35 [06:19<01:02, 12.44s/it]Acc: 0.8750  Avg. train/valid loss: 0.1436/0.4505:  86%|████████▌ | 30/35 [06:31<01:02, 12.44s/it]Acc: 0.8750  Avg. train/valid loss: 0.1436/0.4505:  89%|████████▊ | 31/35 [06:31<00:49, 12.40s/it]Acc: 0.8890  Avg. train/valid loss: 0.1315/0.3856:  89%|████████▊ | 31/35 [06:44<00:49, 12.40s/it]Acc: 0.8890  Avg. train/valid loss: 0.1315/0.3856:  91%|█████████▏| 32/35 [06:44<00:37, 12.41s/it]Saved loss with acc: 0.8889999985694885 | loss: 0.3855701982975006
Acc: 0.8753  Avg. train/valid loss: 0.1328/0.4463:  91%|█████████▏| 32/35 [06:56<00:37, 12.41s/it]Acc: 0.8753  Avg. train/valid loss: 0.1328/0.4463:  94%|█████████▍| 33/35 [06:56<00:24, 12.37s/it]Acc: 0.8888  Avg. train/valid loss: 0.1187/0.3937:  94%|█████████▍| 33/35 [07:09<00:24, 12.37s/it]Acc: 0.8888  Avg. train/valid loss: 0.1187/0.3937:  97%|█████████▋| 34/35 [07:09<00:12, 12.43s/it]Acc: 0.8844  Avg. train/valid loss: 0.1290/0.4077:  97%|█████████▋| 34/35 [07:21<00:12, 12.43s/it]Acc: 0.8844  Avg. train/valid loss: 0.1290/0.4077: 100%|██████████| 35/35 [07:21<00:00, 12.48s/it]Acc: 0.8844  Avg. train/valid loss: 0.1290/0.4077: 100%|██████████| 35/35 [07:21<00:00, 12.62s/it]
airplane     91.40 %
automobile   95.50 %
bird         91.70 %
cat          72.90 %
deer         83.20 %
dog          83.30 %
frog         93.70 %
horse        91.00 %
ship         96.00 %
truck        93.00 %
